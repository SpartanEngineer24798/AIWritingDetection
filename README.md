# AIWritingDetection

This repository contains research on AI Writing Detection conducted in collaboration with MoMA Labs. The codebase was tested on Ubuntu 20.04.6 on a fresh python conda environment.

## Stylometry Based MLP

The Stylometry Based MLP is a project inspired by GLTR and PAN stylometry efforts [https://pan.webis.de/] aimed at detecting split authorship in a given text. This work simplifies their research and focuses on extracting significant stylometric information from AI-generated text and comparing it with human-generated text.

## How to Use

To use this repository, follow the steps below.

First, it is recommended that you use python 3.9 version as the requirements have been calibrated for that version. It is recommended that you either use a venv or conda with python 3.9. Once you have your environment, install all the requirements by calling:

   ```
   pip install -r requirements.txt
   python -m spacy download en_core_web_trf #en_core_web_trf is a spacy module that needs to be downloaded separately
   ```


If you do not have your own data, please use the example data provided inside OpenAI_Data folder. Call datasetmaker.py with the following:
   ```
   python3 datasetmaker.py --path absolute-path-to-/balanced_text_data.csv
   ```
This will let you skip steps 1-5.

1. Create a folder named "input" in the root directory of the project.
2. Within the "input" folder, create a subfolder for each category you want to analyze ("human" and "ai").
3. Place the text files to be analyzed in their respective subfolders. Each text file should be in the format of a ".txt" file.
   - Example structure:
   
     ```
     input
     ├── human
     │   ├── text1.txt
     │   └── text2.txt
     └── ai
         ├── text1.txt
         └── text2.txt
     ```
4. The program will automatically create an "output" folder in the root directory. This folder will contain the extracted features for each text file.
5. Additionally, a "results" folder will be created in the root directory. This folder will store plot images and the MLP checkpoint that will be generated by the code.
6. To run the main program, execute the following command in the terminal:

   ```
   python3 main.py --i input_directory --o output_directory --r results_directory
   ```

   Replace `input_directory` with the path to the "input" folder, `output_directory` with the desired path for the output folder, and `results_directory` with the desired path for the results folder.
   You do not have to provide --o and --r if you are running it for the first time.
   You can also call --only_extraction, --only_clustering, and --only_mlp if you want to only run the respective codes

   The MLP training can be further customized by calling it on its own

   ```
   python3 mlp.py --i input_directory --r results_directory --lr your_rate --alpha your_alpha --patience your_patience
   ```

   The default hyperparameters will be called when the training hyperparameters are not given (these default hyperparameters work well with the data generated from balanced_text_data.csv)

By following these steps, you will be able to analyze the text files, extract stylometric features, and obtain results using the Stylometry Based MLP.

## HowkGPT

HowkGPT is an AI Text detection program created by the Modern Microprocessor Architecture Lab, accessible online at https://howkgpt.hpc.nyu.edu/. The code, howkgpt.py is an automated method of calling the API to check the text items in your input folder against the online classifier. The code is compatible with the input format with the main code.

You can call howkgpt.py by putting the following in the command line interface:

   ```
   python3 howkgpt.py --i input_dir --o output_dir --api <<YOUR_API_KEY>> --counter_limit 3
   ```

Where the input folder is the same as the input used by the main.py, and the output folder is recommended to be custom-created to store the API responses from HowkGPT. Counter limit is an optional variable (can be ignored) to limit the number of requests made to the API. The responses of the API will be saved to the specified output directory as individual json files, and the code will also output a confusion matrix at the end of execution.

Note: as of now, there is no public way of receiving your own API key to use HowkGPT. Please contact the researchers directly if you would like to receive access.

## ChatGPT API

In-house implementation of accessing ChatGPT API is provided for producing HC3-Personalities Dataset.

Note: the data generated over the course of June-July is provided as api_log.txt (for GPT3.5 responses) and gpt4_api_log.txt (for GPT4 reponses).